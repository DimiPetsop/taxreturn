---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# taxreturn

<!-- badges: start -->
[![Travis build status](https://travis-ci.org/alexpiper/taxreturn.svg?branch=master)](https://travis-ci.org/alexpiper/taxreturn)
<!-- badges: end -->

taxreturn is an R package for fetching DNA barcode sequences and associated taxonomic annotations from public databases such as the Barcode of Life Database (BOLD) and NCBI GenBank, curating these sequences and formatting them into training sets compatible with popular taxonomic classifiers used for metabarcoding and marker gene analysis.

## Installation

This package is still in development and not yet available on CRAN.  You can install development version from [GitHub](https://github.com/) with:

```{r}
# install.packages("devtools")
#devtools::install_github("alexpiper/taxreturn")
```

#Current progress:

## Database creation
* get_database(options="bold, "genbank" etc) + some hmmer cleaning?
* clean_database(ie automated filters)
* clean_alignment(remove badly aligend sequences)
* format_datbase(options="blast","RDP","q2","IDTAXA" etc))
* add_sequences(add local db)
* Trim_to_primer_regions - Using insect r package HMM's

## Sample Sheet & Index switching
* Samplesheet_new(options=Miseq, hiseq etc)
* Samplesheet_allcombinations(expand out all combinations)
* switchrate_allcomb(calculate switchrate from expected vs observed)
* switchrate_control(calculate switchrate from control - allow selecting control)

## Primer evaluation
* evaluate_primerbind(use hmm similar to insect r package to locate bind site, then primer miner evaluation)
* plot_primer - Plot the above output* 

## Analysis
Mostly handled by DADA2
evaluate_bias and calibrate_bias - Imported from 

## Plotting
* Mostly hanadled by phyloseq
* summarise_Taxa(samples=c()) - similar to current summarise taxa but allow subsettign to desired samples
* Plot_expectedobserved(allow comparison of fit)

## Summarising
* output detection tables etc - reports
* How many sequences were removed at each stage - Plot of this (Histogram of reductions)
* How many sequences were dereplicated - Plot of dataset redundancy (Histogram of species had 1,2,3,4,5,6,7,8,9,10+ etc)


## Examples

This is a basic example which shows you how to solve a common problem:

* Step 1 - Downlaod sequences for BOLD and genbank
* Step 2 - Convert bold to have genbank accessions using taxizedb and merge fastas
* Step 3 - clean sequences using a PHMM of COI - Include a RDS data file already trained on the midori set
* Step 4 - cluster and Purge misannotated sequences using insect::Purge
* Step 5 - Fetch heirarchial taxonomy using taxizedb
* Step 6 - Trim to amplicon region using insect::VirtualPCR


UPDATESD

```{r example, eval=FALSE, include=FALSE}
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)

## Fetch sequences from GenBank - Might also be good having an output="all" option
fetchSeqs("Scaptodrosophila", database="genbank",downstream=TRUE,quiet=FALSE, downto="Species", marker="COI OR COI OR COX1 OR COXI", output = "gb-binom",compress=FALSE, cores=3)

## Fetch sequences from BOLD
fetchSeqs("Scaptodrosophila", database="bold",downstream=TRUE,quiet=FALSE, downto="Species", marker="COI-5P", output = "gb-binom",compress=FALSE, cores=3)

#read in all fastas and merge
gbSeqs <-  readDNAStringSet(sort(list.files("genbank", pattern = ".fa", full.names = TRUE)))
boldSeqs <-  readDNAStringSet(sort(list.files("bold", pattern = ".fa", full.names = TRUE)))
mergedSeqs <- append(gbSeqs, boldSeqs, after=length(gbSeqs))
uniqSeqs <- mergedSeqs[unique(names(mergedSeqs)),] # Remove those sequnce names that are identical across both databases
  

#Filter using hidden markov model

#build PHMM from midori longest - sequences need to be same length
midori <-  readDNAStringSet("MIDORI_LONGEST_20180221_COI.fasta")
Scapto_midori <- as.DNAbin(midori[str_detect(names(midori),pattern=";Scaptodrosophila;"),])
folmer <- virtualPCR(Scapto_midori, up = "TITCIACIAAYCAYAARGAYATTGG",down= "TAIACYTCIGGRTGICCRAARAAYCA",cores=3, rcdown = TRUE, trimprimers = TRUE)
model <- derivePHMM(folmer)

#Clean taxa
testSeqs <-  readDNAStringSet("test_set.fa")
filtered <- clean_seqs(testSeqs, model,minscore = 100, minamplen = 50, maxamplen = 1000, shave=TRUE,maxNs = 0)

#filter using insect::purge - Could wrap this in a function for ease of use?
db <- taxonomy(db = "NCBI", synonyms = TRUE)

#Save old names into attributes
attributes(filtered)$oldnames <- names(filtered)
#Get names in format for Pugre
names(filtered) <- names(filtered) %>%
  str_split_fixed(";",n=2) %>%
  as_tibble() %>%
  pull("V1") 
purged  <- purge(filtered, db = db, level = "species", confidence = 0.5,
                  threshold = 0.99, method = "farthest")

#Restore old names
names(purged) <- attributes(purged)$oldnames

#Prune group sizes down to 5 #Add a discardby=Random, or discardby=Length to the  function
pruned <- prune_groups(purged,maxGroupSize = 5,quiet = FALSE)

#Check alignments
filt_aligned <- pruned %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet
filt_aligned <- AlignSeqs(filt_aligned)
BrowseSeqs(filt_aligned)


#Filter out misannotated terms and species that arent binomials - Maybe this can be done during groups as well?
filtseqs <- filter_taxa(mergedseqs,minlength=200,maxlength=1000,unique=TRUE,binomials=TRUE, removeterms=c("sp.","cf.","NA"))

#Resolve taxonomy - insufficiently identified, synonyms

#Filter_phmm
#calls aphid to filter with a prebuilt PHMM

#Trim to primer region using virtualPCR from insect package
amplicon <- virtualPCR(filtseqs, up = "ACWGGWTGRACWGTNTAYCC",down= "ARYATDGTRATDGCHCCDGC",cores=3, rcdown = TRUE, trimprimers = TRUE)
writeFASTA(amplicon,"gb_trimmed.fa")

#Resolve taxonomic names using taxize
#data source 4 = NCBI - To see more data sources use gnr_datasources()
names_resolved <- gnr_resolve(names,best_match_only = TRUE, cannonical=TRUE,preferred_data_sources = "4")
#also resolve synonyms using - See scotts code

#replace with purrr
for (i in 1:nrow(names_resolved)){
  names(merged) <- names(merged) %>%
    str_replace(pattern=names_resolved$user_supplied_name[i],replacement=names_resolved$matched_name[i])
}

#Merge in inhouse sequences
merged <-  readFASTA("merged_cleaned.fa")
inhouse <- readFASTA("inhouse/Inhouse_taxonomy_trimmed.fasta")

merged2 <- join(merged, inhouse)
writeFASTA(merged2,"merged_cleaned_inhouse.fa")

#write out format for training

#format_ref function


```
