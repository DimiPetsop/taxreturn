---
title: "taxreturn-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{taxreturn-vignette}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval=FALSE
)
```

```{r setup, echo=FALSE}
library(taxreturn)
library(Biostrings)
library(tidyverse)
```

# Introduction

As with conventional DNA barcoding, accurate taxonomic assignment in metabarcoding studies relies on a well-curated reference database of DNA marker sequences to compare query sequences against. The primary public nucleotide databases of relevance to eukaryotic metabarcoding are the NCBI GenBank database and the Barcode of Life Data System (BOLD), both of which taxreturn supports. While GenBank hosts greater overall sequence data, BOLD represents a more curated DNA barcoding database that aims to maintain consistent links between sequences, validated morphological specimens, and associated specimen collection metadata.

Despite the best efforts of submitters, both these databases have well documented issues with barcode sequences being either insufficiently annotated, annotated with the incorrect species, or multiple morpho-species assigned to the same DNA barcode, which may reflect misidentifications or the existence of species complexes.While some metabarcoding studies have responded to the aforementioned issues by exclusively using in-house reference databases for taxonomic assignment [90, 93–95], because many insect surveillance programmes aim to detect species that are not locally present, the reliance on public data to supplement in-house sequences may be unavoidable. Curating public reference data is therefore crucial for ensuring the robustness of a metabarcoding analysis, and this is the role that the taxreturn package aims to fulfil.

The main steps of the taxreturn workflow are as follows:

* Download relevant barcode sequences and Mitochondrial genomes from BOLD and Genbank
* Use a profile hidden markov model trained on a reference alignment for the locus to remove non-homologous loci and cut the desired region from mitogenomes/longer sequences
* Use sequence similarity clustering to remove misannotated sequences (ie 99% similar sequences should share species level taxononmy)
* Resolve taxonomic synonyms using a reference taxonomy database (NCBI or open tree of life)
* Prune sequences from over-represented groups
* Reformat into a taxonomic hierarchy format (ie Kingdom;phylum….;Species) appropriate for metabarcoding classifiers.

# A Worked example

The following vignette will run through an example analysis of retrieving insect COI barcode sequences and mitochondrial genomes, curating these, and outputting a reference database.

## Install & load package

First, make sure that the devtools, Biostrings and ape packages are installed and up to date. Then install and load the latest development version of the taxreturn package from GitHub as follows:

```{r eval=FALSE}
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)
```

## Fetching sequences from GenBank and BOLD

The first step is to retrieve public reference data sequences from NCBI Genbank and BOLD. This can be done with the fetchSeqs function, which wraps an interface to entrez and BOLD API's respectively. This function can either take a single higher level rank, i.e. the family 'Trioza', or it can take a vector of taxon names, such as the species contained on a priority pest list or those of conservation concern.

The downstream option lets the function know if you want to conduct searches and output fasta files using the input rank, or at a taxonomic rank downstream of it, i.e. Species. The downto option then determines what that downstream rank is. This functionality is important for getting around server limits when conducting large searches for example 'Insecta', however comes with some computational overhead when downloading few taxa.

The marker option determines what will be in the search, note that the naming of loci differs between Genbank and bold so i suggest conducting a test search on their respective websites to confirm the desired marker.

The compress option toggles whether to output as a gzipped fasta file to save space. All further functions in this package should be capable of handling gzipped files.

Finally, the cores option determines how many cores to use when downloading sequences, using more cores can speed up searches. *note - i dont believe cores is currently working properly so use 1 core for now* 

Depending on the amount of sequences you are downloading, and the speed of your internet connection this step can take from minutes to hours, i suggest running this overnight for large searches with over a million sequences.

## Download sequences from NCBI GenBank 

```{r Download all sequences, eval=FALSE, include=TRUE}
## Fetch sequences from GenBank by searching for a taxon name
fetchSeqs("Scaptodrosophila", database="genbank", out.dir="genbank", downstream="species", marker="COI OR COI OR COX1 OR COXI", quiet=FALSE, output = "gb-binom", compress=TRUE)

## OR fetch sequences from a species list
spp_list <- readLines("species_list.txt")
fetchSeqs(spp_list, database="genbank", out.dir="genbank", quiet=FALSE, output = "gb-binom", marker="COI OR COI OR COX1 OR COXI", compress=TRUE)
```


## Download sequences from BOLD

```{r Download BOLD Sequences, eval=FALSE, include=TRUE}
## Fetch sequences from BOLD by searching for a taxon name
fetchSeqs("Scaptodrosophila", database="bold", out.dir="bold", downstream="species", quiet=FALSE, marker="COI-5P", output = "gb-binom", compress=TRUE)

## OR fetch sequences from a species list
spp_list <- readLines("species_list.txt")
fetchSeqs(spp_list, database="bold", out.dir="bold", quiet=FALSE, marker="COI-5P", output = "gb-binom", compress=TRUE)
```

## Download mitochondrial genomes from GenBank

We can also use these functions to download mitochondrial genomes, and use the PHMM implemented in the clean_seqs function to pull out our target region from the genome.

The fetchSeqs function accepts a special input argument of marker="mitochondria" to do this.

```{r Download mitochondria, eval=FALSE, include=TRUE}
# Fetch mitochondrial genomes from genbank by searching for a taxon name
fetchSeqs("Scaptodrosophila", database="genbank", out.dir="genbank", quiet=FALSE, marker="mitochondria", output = "gb-binom", compress=TRUE)

# Fetch mitochondrial genomes from genbank by searching for a taxon name
fetchSeqs("Scaptodrosophila", database="genbank", out.dir="genbank", quiet=FALSE, marker="mitochondria", output = "gb-binom", compress=TRUE)
```

# Curating public reference sequences

Due to the aforementioned issues with misannotated sequences in public reference databases we will use a number of filtering steps.

## Removing non-homologous sequences

The first 



In order to reduce bias involved in mapping sequences to a single reference sequence, we will align them to a profile hidden markov model of the gene that uses a probablistic framework to take into account a wider range of diversity. To make this model we will use the aphid R package, and a curated alignment of insect COI sequences obtained from the Midori dataset and trimmed to the folmer region.

A pretrained model of the conventional COI barcode or 'folmer' region can be loaded from the package data as below. This model was trained on the midori longest dataset of all COI sequences.

```{r load model}
#model <- data("model", package="taxreturn")
load("C:/Users/ap0y/Dropbox/R/taxreturn/data/model.rda")
```

However if you are workign with a different barcode locus, or if you wish to improve accuracy by training on a specific taxonomic group you can train a new PHMM model using the aphid R package as below:

Note: if you are using a public dataset as a reference alignment to build the model, it may be worth further curating it manually first, as a poor reference alignment will produce a poor model and greatly affect downstream analysis

```{r build PHMM, eval=FALSE}
# Load necessary packages
library(Biostrings)
library(insect)
library(aphid)

# Read in sequence dataset to be used in model training
seqs <-  readDNAStringSet("MIDORI_LONGEST_20180221_COI.fasta")

# Trim the sequences to the amplified region using a virtual PCR
amplicon <- insect::virtualPCR(seqs,
                               up = "TITCIACIAAYCAYAARGAYATTGG",  #Forward primer
                               down= "TAIACYTCIGGRTGICCRAARAAYCA", #Reverse primer
                             cores=1, rcdown = TRUE, trimprimers = TRUE)

#Only retain amplicons of the appropriate length (in this case 658bp)
amplicon_filtered <- amplicon[lengths(amplicon) == 658]
model <- aphid::derivePHMM(amplicon_filtered)
```

Now that we have our train PHMM model, we will use the cleanseqs function with the model to remove non-homolgous sequences and extract the target locus from mitochondrial genomes and longer sequences.

Firstly we will merge the sequences from each database together. As BOLD and GenBank share a number of sequences, we subset the merged file to only the unique sequences to speed things up.

As we only wish to look at the sequence data contained within the range of our alignment model (in this case the folmer region of COI), we use the option shave=TRUE to remove all bases to the left and right of the model.

```{r clean seqs}
#read in all fastas and merge
library(Biostrings)

seqs <- c(readDNAStringSet(list.files("genbank", pattern = ".fa", full.names = TRUE)),
                readDNAStringSet(list.files("bold", pattern = ".fa", full.names = TRUE))
                )

uniqSeqs <- seqs[unique(names(seqs)),] # Remove those sequnce names that are identical across both databases

#remove non-homologous sequences
filtered <- clean_seqs(uniqSeqs, model, minscore = 100, cores=1, shave=TRUE)
```

## Resolve Contaminated sequences and misannotated taxonomy

The other main form of misannotation that can effect metabarcoding datasets is incorrect taxonomy for the reference sequences. To resolve this issue, we use the purge function from the insect R package, which clusters sequences at a specific similarity threshold (in this case 99% simularity), and compares the heirarchial taxonomy within clusters. When the taxonomy of a sequences diverges from the other sequences in its cluster, it is removed as a putative misannotation. The confidence required the remove a sequence can be adjusted. In this case we use a confidence threshold of 0.8, which indicates the putative misannotated sequence must diverge from 4/5 other sequences in its cluster to be removed from the dataset.

insect::purge requires specifically formated names, so we do some transformations to get the names in this format, retaining the old names in the attributes. These old names are then restored following removal of missanotated sequences

```{r insect purge}
#Download the NCBI taxonomy database
db <- insect::taxonomy(db = "NCBI", synonyms = TRUE)

#Filter the taxonomy database to remove contaminants and 
db <- db %>%
  dplyr::filter(!rank %in% c("varietas","subspecies","species subgroup")) %>%
  dplyr::filter(!str_detect(name, fixed("sp."))) %>%
  dplyr::filter(!str_detect(name, fixed("spp."))) %>%
  dplyr::filter(!str_detect(name, fixed("aff."))) %>%
  dplyr::filter(!str_detect(name, fixed("nr."))) %>%
  dplyr::filter(!str_detect(name, fixed("bv."))) %>%
  dplyr::filter(!str_detect(name, fixed("cf."))) %>%
  dplyr::filter(!str_detect(name, fixed("nom."))) %>%
  dplyr::filter(!str_detect(name, fixed("nud."))) %>%
  dplyr::filter(!str_detect(name, fixed("environment"))) %>%
  dplyr::filter(!str_detect(name, fixed("undescribed"))) %>%
  dplyr::filter(!str_detect(name, fixed("unverified"))) %>%
  dplyr::filter(!str_detect(name, fixed("unclassified"))) %>%
  dplyr::filter(!str_detect(name, fixed("uncultured"))) %>%
  dplyr::filter(!str_detect(name, fixed("unidentif"))) %>%
  dplyr::filter(!str_detect(name, fixed("NA"))) %>%
  dplyr::filter(!str_detect(name, fixed("error"))) %>% 
  dplyr::filter(!str_detect(name,"[0-9]"))%>% 
  dplyr::filter(!str_detect(name,"[:punct:]"))

remove <- names(filtered)  %>% 
  str_split_fixed(";", n = 2) %>% 
  as_tibble() %>%
  filter(V2 %in% db$name) %>%
  unite(names,c("V1","V2"),sep=";")

subset <- filtered[names(filtered) %in% remove$names]

#Save names into attributes
attributes(filtered)$oldnames <- names(filtered)

#Transform names to format appropriate for insect::purge
names(filtered) <- names(filtered) %>%
  str_split_fixed(";",n=2) %>%
  as_tibble() %>%
  pull("V1") 

#Retain unique names only
filtered <- insect::subset.DNAbin(filtered, subset = !duplicated(names(filtered)))

#Cluster and remove misannotated sequences
purged  <- insect::purge(filtered, db = db, level = "species", confidence = 0.8,
                  threshold = 0.99, method = "farthest")

#Restore old names
names(purged) <- attributes(purged)$oldnames
```

## Resolve synonyms

Classification of sequences into reference taxonomy can be complicated by the existence of taxonomic synonyms. To resolve this we use the GBIF server to check each name to see if it represents a currently valid taxa. If it represents a synonym, the name is replaced with the accepted taxon name.

The options to consider here, is what to do with the synonyms that dont exist in the NCBI taxonomy, in this case we ignore the fact taxa are missing from the NCBI taxonomy and rename them anyway

```{r resolve synoynms}
resolved <- resolve_taxonomy(purged, subspecies=FALSE, quiet=FALSE, missing="ignore", higherrank=FALSE, fuzzy=TRUE)

#Check for differences in names
names(resolved)[which(!names(resolved) %in% names(purged))]
```


## Prune large groups

In many cases groups of taxa are over-represented in databases, which can slow down and in some cases bias the taxonomic assignment process. Here we prune over-represented groups down to 5 sequences. Here we have the option of discarding these sequences by length (ie removing smaller sequences first), or randomly.


```{r prune groups}
#Prune group sizes down to 5, removing all identical sequences first
pruned <- prune_groups(resolved, maxGroupSize = 5, discardby="length", dedup=TRUE, quiet = FALSE)
```

## Trim to primer regions

Next we will trim the sequences to the primer regions we use for metabarcoding using the virtualPCR function from the insect R pacakge

```{r trim to primer regions}
#Trim to primer region using virtualPCR from insect package
amplicon <- insect::virtualPCR(pruned, up = "ACWGGWTGRACWGTNTAYCC", down= "ARYATDGTRATDGCHCCDGC", cores=2, rcdown = TRUE, trimprimers = TRUE)

insect::writeFASTA(amplicon, file="cleaned_amplicon.fa.gz", compress=TRUE)
```

# Output trained classifiers


```{r train and output}
#Reformat to complete taxonomic heirarchy 
heirarchy <- reformat_heirarchy(amplicon, db=db, quiet=FALSE)

#Reformat to Kingdom to genus heirarchy suitable for assigntaxonomy classifier in DADA2
dada2_gen <- reformat_dada2_gen(amplicon, db=db, quiet=FALSE)

#Reformat to genus species binomials as suitable for assignSpecies in DADA2
dada2_spp <- reformat_dada2_spp(amplicon)

# Train IDTAXA
trainingSet <- taxreturn::train_idtaxa(amplicon)
#Write out training set
saveRDS(trainingSet, file="reference/idtaxa.rds")

```


# Summarise number of taxa in database

```{r summary}
summary <- tax2tree(heirarchy, output="treedf")
```

# Get top hit identity distribution for dataset

The top hit identity distribution (THID) of Edgar et al 2018 offers a method of Edgar et al 2018 offers a method for sumarising the distances between a reference database and a query dataset. Here we summarise how well our new reference database contains the genetics from an insect metabarcoding dataset. Taxreturn contains a wrapper around the NCBI blast utilities to make this easy.

```{r THID}
seqtab <- readRDS("seqtab_final.rds")

seqs <- insect::char2dna(colnames(seqtab))

# Check if blast is installed. If not, install a local version
if(all(Sys.which("blastn")=="")){
  blast_install(dest.dir="bin")
}

# Create blast Database
makeblastdb("cleaned_amplicon.fa.gz")

THID <- blast_top_hit(query=seqs, db="cleaned_amplicon.fa")

# plot histogram
gg.THID <- THID %>%
  ggplot(aes(x=pident))+ 
  geom_histogram(colour="black") + 
  ggtitle("Top Hit Identity Distribution") +
  xlab("Top Hit Identity") + 
  ylab("Sequences")

```


```{r extra summary}
db <- insect::readFASTA("heirarchial.fa.gz")

library(tidyverse)
names <- names(db) %>%
  str_split_fixed(";", n=8) %>%
  as_tibble() %>%
  tidyr::separate(V1, into=c("Acc", "taxid")) %>%
  magrittr::set_colnames(c("Acc", "taxid", "kingdom", "phylum", "class", "order", "family", "genus", "species")) %>%
  mutate(species = str_replace(species, ";", ""))


summary <- names %>%
  summarise(sequences = n_distinct(Acc),
            kingdom = n_distinct(kingdom),
            phylum = n_distinct(phylum),
            class = n_distinct(class),
            order = n_distinct(order),
            family = n_distinct(family),
            genus = n_distinct(genus),
            species = n_distinct(species)
            )

write_csv(summary, "db_summary.csv", append = FALSE)
write_csv(names, "db_all_taxa.csv", append = FALSE)



```
