---
title: "protax"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{protax}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval=FALSE,
  root.dir= rprojroot::find_rstudio_root_file()
)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

```

```{r setup}
library(taxreturn)
library(tidyverse)
```

# Introduction

This vignette is a R based version of the PROTAX tutorial. This code requires a perl install. The taxreturn package contains wrapper functions for using these perl utilities

functions to add
 * Classify sequences
 * Install protax

# Generate training data


Get taxonomy as per https://github.com/alexcrampton-platt/screenforbio-mbc/
```{r get taxonomy crampton}
library(taxize)
taxon_list <- taxizedb::downstream("Insecta",db="ncbi",downto="species")
taxon_sp <- as.data.frame(taxon_list[1])[,1]
taxon_class <- taxizedb::classification(taxon_sp, db="ncbi",return_id=FALSE)

taxon_tab <- cbind(taxon_class)

#This is what screenbio pipeline requires
taxon_tab_out <- taxon_tab %>% 
  select(phylum, class, order, family, genus, species) %>%
  mutate(species = str_replace(species, pattern=" ", replacement="_")) 
  
write.table(taxon_tab_out,paste0("Insecta","_ncbi_taxonomy.txt"),sep="\t",col.names=FALSE,row.names=FALSE,quote=FALSE)

## Either use the screenbio perl scripts or reformat in R



tax_reformat <- taxon_tab_out %>%
  mutate(species = str_replace(species, pattern=" ", replacement="_")) 

%>%
  unite(lineage, c("phylum","class","order","family","genus","species"))
  #filter(class=="Insecta" | tax_name=="Insecta") %>%
  #select(1:7) %>% 
  gather("key", "value") 

%>%
  filter(!is.na(value)) %>% 
  unite(2:3, col="taxname", sep="=") %>%
  group_by(tax_id) %>%
  summarize(lineage= paste(taxname, collapse="; ")) %>%
  separate(lineage, into = c("taxname", "parent"), sep=";")


```

Perl /protaxscripts/maketaxonomy.pl gives
    0	0	0	root
    1	0	1	Diptera
    2	1	2	Diptera,Drosophilidae
    3	2	3	Diptera,Drosophilidae,Gitonides
    4	3	4	Diptera,Drosophilidae,Gitonides,Gitonides
    5	2	3	Diptera,Drosophilidae,Chymomyza
    6	5	4	Diptera,Drosophilidae,Chymomyza,Chymomyza
    
    
Basically this script seems to just reformat it to similar to my script below, but they also keep the taxon heirarchy seperated by a ,


perl /protaxscripts/taxonomy_priors.pl gives:

0       0       0       root    1.0000000000
1       0       1       Diptera 1.0000000000
2       1       2       Diptera,Drosophilidae   1.0000000000
3       2       3       Diptera,Drosophilidae,Gitonides 0.0416666667
4       3       4       Diptera,Drosophilidae,Gitonides,Gitonides       0.0416666667
5       2       3       Diptera,Drosophilidae,Chymomyza 0.0416666667
6       5       4       Diptera,Drosophilidae,Chymomyza,Chymomyza       0.0416666667
7       2       3       Diptera,Drosophilidae,Cladochaeta       0.0416666667
8       7       4       Diptera,Drosophilidae,Cladochaeta,Cladochaeta   0.0416666667

This next script taxonomy_priors.pl seems to just give an even prior by dividing the taxa by the number of options at that level

perl /protaxscripts/thintaxonomy.pl 1 gives:
0       0       0       root    1.0000000000
1       0       1       Diptera 1.0000000000

the number decides the level to prinbt



Our example taxonomy tree is in file ‘example_taxonomy.txt’ and the taxonomic information of our reference sequences is in file ‘example_trainseqid2taxoname.txt’. Taxonomy tree file is a text file consisting of four columns separated by space or tab in each line, where nodeid and nodepid are the numeric node identifiers. They can be in principle any integers but the nodeid of the root node must be 0. Nodepid is the parent nodeid (for root node it is the root node itself). Level is the level of the node in taxonomy (root node has level 0) and taxname is the taxonomic name. Any unique character string can be used for the taxonomic name but it should not contain any spaces or tabs (only the first part separated by space will be used as a name). The structure of the taxonomy is constructed based on the (nodeid,nodepid) pairs but the reference sequence data is linked into taxonomy based on the taxname. Taxonomy file does not have any header line so the first row contains already the first values.

```{r display taxonomy}
tax_tree <- readr::read_tsv("../protax/data/example_taxonomy.txt", col_names=FALSE) %>%
  magrittr::set_colnames(c("nodeid", "nodepid", "level", "taxname"))
head(tax_tree)


#get taxonomy tree
library(tidyverse)
ranked_lineage <- get_ranked_lineage(db="NCBI", synonyms=TRUE) # Synonyms==FALSE is removing many real samples!

#Filter and transform taxonomy tree

tax <- ranked_lineage %>%
  filter(class=="Insecta" | tax_name=="Insecta") %>%
  select(1:7) %>% 
  gather("key", "value", 2:7) %>%
  filter(!is.na(value)) %>% 
  unite(2:3, col="taxname", sep="=") %>%
  group_by(tax_id) %>%
  summarize(lineage= paste(taxname, collapse="; ")) %>%
  mutate(lineage = str_replace(lineage, pattern="tax_name=", ))

%>%
  separate(lineage, into = c("taxname", "parent"), sep=";")

%>% # Change here to instead take out family= and replace with columns
  
  
  
  separate(parent, into=c("level", "parent"), sep="=") %>%
  mutate(level = trimws(level)) %>%
  mutate(taxname = taxname %>%
           str_replace(pattern="tax_name=", replacement = "")) %>%
  mutate(level = case_when(
    is.na(level) ~ 0, #Set the root
    level=="class" ~ 1,
    level=="order" ~ 2,
    level=="family" ~ 3,
    level=="genus" ~ 4,
  )) %>%
  filter(!is.na(level)) %>%
  mutate(parent=case_when(
    is.na(parent) ~ "root", # rename the root
    TRUE ~ parent
  ))


#Filter bad taxnames
tax2 <- tax %>%
  dplyr::filter(!str_detect(taxname, fixed("sp."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("spp."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("aff."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("nr."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("bv."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("cf."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("nom."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("nud."))) %>%
  dplyr::filter(!str_detect(taxname, fixed("environment"))) %>%
  dplyr::filter(!str_detect(taxname, fixed("undescribed"))) %>%
  dplyr::filter(!str_detect(taxname, fixed("unverified"))) %>%
  dplyr::filter(!str_detect(taxname, fixed("unclassified"))) %>%
  dplyr::filter(!str_detect(taxname, fixed("uncultured"))) %>%
  dplyr::filter(!str_detect(taxname, fixed("unidentif"))) %>%
  dplyr::filter(!str_detect(taxname, fixed("NA"))) %>%
  dplyr::filter(!str_detect(taxname, fixed("error"))) %>% 
  dplyr::filter(!str_detect(taxname,"[0-9]"))%>% 
  dplyr::filter(!str_detect(taxname,"[:punct:]"))


# replace parent names with the nodeid of the parent

tax3 <- tax2 %>%
  left_join(
    tax2 %>%
      select(tax_id, taxname) %>%
      rename(parent = taxname) %>%
      rename(nodepid = tax_id) %>%
      select(parent, nodepid)
  ) %>%
  mutate(tax_id = tax_id %>% str_replace("50557", "0")) %>%
  mutate(nodepid = case_when(
    level==0 ~ 0,
    level > 0 ~ as.double(nodepid)
  )) %>%
  filter(!is.na(level)) %>%
  rename(nodeid = tax_id) %>%
  select(nodeid, nodepid, level, taxname)  %>%
  mutate(taxname = taxname %>% str_replace(pattern=" ", replacement="_")) %>%
  filter(!is.na(nodepid))

# Add priors
tax3 <- tax3 %>%
  mutate(priors = 1)

#split species
tax3 <- tax3 %>%
  mutate(taxname = case_when(
    level==4 ~ str_split_fixed(taxname, "_", n=2) %>% as_tibble %>% pull(V2),
    TRUE ~ taxname
    
  ))


write_tsv(tax3, path="../protax/insecta_taxonomy.txt", col_names = FALSE)

```


Next part of script

1- First part of the script finds matches between the taxonomy and reference sequences using the taxon names to create trainseqid2taxname.txt

2- The next part of the script takes an input of a method of defining the reference sequences, and a number of reference sequences to choose, as well as optional weightings, and creates the rseqs.txt  file with  or without the weightings

3- The next part of the script takes an option for how many samples to take from the taxonomy, and generates the trainsamples.txt which contains the prior probability . Need to work out why we need to subsample the trainign set like this and how many subsamples should i use?

4- Generates the pairwise sequence similarities from the trainseq fasta using either kmer::mbed or kmer::kdistance (slightly more accurate), depending on the size of the dataset

5- generate the design matrix - this takes in the taxonomy, training samples and sequence similarities etc and geenerates the design matrix for MCMC


## Create trainseqid2taxname

The file containing the taxonomic information of the reference sequence data (example_trainseqid2taxname.txt) contains two fields separated by space or tab. The file doesn't have a header line. For each seqid there should be only one taxname which is the most specific taxonomic classification. Like seqid, also taxname should be unambiguous and unique. Lower level taxonomic classes (taxonomy nodes towards the root of the tree) of each sequence can be obtained based on the taxonomy tree.

```{r}
#trainseq2taxid
#ref_tax <- readr::read_tsv("../protax/data/example_trainseqid2taxname.txt", col_names=FALSE)%>%
#  magrittr::set_colnames(c("seqid", "taxname"))
#head(ref_tax)

#inputs: Taxonomy (table, or tree object?), refseqs (DNAbin)

refseqs <- insect::readFASTA("../pruned.fa.gz")

trainseqid2taxname <-  names(refseqs) %>%
    stringr::str_split_fixed(";",n=2) %>%
    tibble::as_tibble() %>%
    tidyr::separate(col=V1,into=c("seqid","nodeid"),sep="\\|") %>%
    dplyr::rename(species = V2) %>%
    dplyr::mutate(nodeid = as.numeric(nodeid)) %>%
  tidyr::separate(species, into=c("kingdom", "phylum", "class", "order", "family", "genus", "taxname"), sep=";") %>%
  select(seqid, taxname) %>%
  mutate(seqid = str_replace_all(seqid, pattern=" ", replacement="")) %>%
  mutate(taxname = str_split_fixed(taxname, "_",n=2) %>% as_tibble() %>% pull(V2))

#filter to only those in the taxonomy
trainseqid2taxname <- trainseqid2taxname %>%
  mutate(taxname = str_replace_all(taxname, pattern = " ", replacement = "")) %>%
  filter(!str_detect(seqid, "#")) %>% 
  filter(!taxname=="") %>%
  filter(taxname %in% tax3$taxname) 

write_tsv(trainseqid2taxname, path="../protax/insecta_trainseqid2taxname.txt", col_names = FALSE)
```

## Define representative sequences

Each node of the taxonomy is associated with the set of representative sequences. These contain a subset or all of the reference sequence data. There are three possibilities to define the representative sequences:
1. using all available reference sequences 
2. selecting a random subset of reference sequences 
3. using clustering with threshold for pairwise sequence similarity of reference sequences 

The corresponding Perl scripts are get_reference_sequences_all.pl, get_reference_sequences_random.pl, and get_reference_sequences_clustering.pl. Please note that these are the three ways to define the set of representative sequences automatically at the moment and there is no guarantee that the resulting set would be optimal. Since the classification of a new sequence is based on the representative sequences, the selection process is important. As the name ‘representative sequences’ implies, they should be selected so that they characterize the entire taxon. Here is an example of the case for limiting the number of representative sequences by using a random subset of reference sequences. Our example taxonomy has 2 levels and here we define that each node may have at most 10 representative sequences from its child nodes. This number must be specified for each level. Although in the example below we have the same number two times, it is possible to define different number for each level. The order is from the most specific node to the root. The number before the output file ‘my_rseqs.txt’, here defined to be 1, is the seed value for the random number generator.


```{r protax get reference sequences}
protax_get_reference_sequences(install ="protax",
                               taxonomy = "/protax/Insecta_ncbi_tax_priors.txt",
                               trainseq2taxid =  "/protax/insecta_trainseqid2taxname.txt",
                               method = "random", 
                               levels = 4,
                               max_per_level = 10,
                               output = "/protax/insecta_rseqs.txt",
                               seed = 1)
```


In case the number of available reference sequences is smaller than the user defined number (like in our example data), as many representative sequences as possible are included. Output file has one line for each node and each line consists of three columns where the first one is node id, the second column lists the representative sequences of the node, and the third column contains the weights of the representative sequences

```{r output myrseqs}
my_rseqs <- readr::read_tsv("../protax/data/my_rseqs.txt", col_names=FALSE) %>%
  magrittr::set_colnames(c("nodeid", "refseqs","weights"))
head(my_rseqs)

my_rseqs <- readr::read_tsv("../protax/insecta_rseqs.txt", col_names=FALSE) %>%
  magrittr::set_colnames(c("nodeid", "refseqs","weights"))
head(my_rseqs)
```

The third column is optional for PROTAX, in case it is missing, each representative sequence has a default weight 1. For the first two selection processes (all and random), the weight is the inverse number of the representative sequences coming from each child of a node. This results that each child node has the same importance when computing the average of pairwise sequence similarities regardless of the differences in the number of representative sequences coming from different child nodes. So in effect, the mean similarity is the mean of means in the 9 corresponding PROTAX covariate. When the selection of representative sequences is based on clustering, the weight is the size (number of sequences) of each cluster.

## Sample the taxonomy to get training data

In this example, we generate 100 samples representing the nodes of the taxonomy. Each node is associated with a training sequence. The details how the sampling is done can be found in the manuscript. In the present implementation, only leaf nodes of the taxonomy are sampled. The number of samples should represent the taxonomy, here we use only 100 samples because the example taxonomy and the reference data set are tiny and the purpose of the example is mainly to demonstrate the syntax of all commands.

```{r generate training data}
# Why does this need to be done?

#Also should be able to have one big function that takes in a DNAbin training set and conducts all these scripts on them - perhaps this should be contained within an S4 object?

protax_generate_training_data(install ="protax",
                              taxonomy ="/protax/insecta_taxonomy.txt",
                              trainseq2taxid = "/protax/insecta_trainseqid2taxname.txt",
                              repseqs = "/protax/insecta_rseqs.txt",
                              samples = 100,
                              output = "/protax/insecta_trainsamples.txt",
                              seed=1)
```

The number 1 after the number of training samples (100) is the seed for random number generator. The next parameter is yes/no indicating whether sequences to be ignored when calculating sequence similarities from the randomly selected training sequence are included in the output file. This information can be reconstructed based on the taxonomy and the other fields of the file, so it should not be selected unless there is a reason for doing so. With large data sets, the amount of this extra information can be excessive resulting in large output files. The last argument of the command is the name of the output file.

Each line of the output file consists of 6 columns:

```{r output myrseqs}
my_traindata <- readr::read_delim("../protax/data/my_trainsamples.txt", col_names=FALSE, delim=" ") %>%
  magrittr::set_colnames(c("weight", "nodeid","priprob","nodeclass", "rnodeid", "trainseqid" ))
head(my_traindata)
```

The value for the first column weight is 1, nodeid is the randomly sampled node and priprob is the associated prior probability of this node. Nodeclass gives information of the type of the node, there are 4 classes:

* nseq2 : node is a known taxon and has at least 2 reference sequences
* nseq1 : node is a known taxon but has only 1 reference sequence 
* nseq0 : node is a known taxon but doesn't have any reference sequences 
* unk : node represents an unknown taxon

If nodeclass is nseq2, it has been possible to pick training sequence directly from the sequences belonging to nodeid. In other cases, another node (rnodeid in 5th column) has been randomly selected among the closest neighbors of the original node (nodeid) which is at the same level and has sufficient amount of reference sequences (1 or 2 depending on the case). The details of the process can be found in our manuscript. The new node will mimick the originally sampled node. For nodeclass nseq1, additional information is needed regarding the reference sequence and this information is included in the 4th column field separated by a comma from the nodeclass, as an example nseq1,seqid. The last column is the id of the training sequence. If the 6th argument is 'yes' instead of 'no' for generate_training_data.pl, there will be 7th column in the output file which lists all sequences to be deleted when computing sequence similarities for the training sample in the present line.

## Get pairwise sequence similarities

the mbed approach of Blackshields, G., Sievers, F., Shi, W., Wilm, A., & Higgins, D. G. (2010). Sequence embedding for fast construction of guide trees for multiple sequence alignment. Algorithms for molecular biology : AMB, 5, 21. doi:10.1186/1748-7188-5-21

For n sequences, the kdistance operation has time and memory complexity O(n2) and thus can become computationally infeasible when the sequence set is large (e.g. > 10,000 sequences). As such, the kmer package also offers the function mbed, that only computes the distances from each sequence to a smaller (or equal) sized subset of ‘seed’ sequences (Blackshields et al., 2010). The default behavior of the mbed function is to select t=(log2n)2 seeds by clustering the sequences (k-means algorithm with k=t), and selecting one representative sequence from each cluster.

All vs all blast or diamond blast would work - similar to how they do it in the PROTAX paper

Would be nice to look at the concordance between the default sequence similarities in the tutorial, the kdistance similarities, and the mbed similarities measures - so do this with the example sequences

```{r}
library(tidyverse)
seqs <- insect::readFASTA("../protax/data/example_trainseq.fasta")


#Tutorial version (BLAST)
sim_tutorial <- readr::read_tsv("../protax/data/example_trainseqsim.txt", col_names=FALSE) %>%
  magrittr::set_colnames(c("seqid1", "seqid2", "sim"))%>% 
  mutate(measure = "blast")

#kdistance version
sim_kdist <-  kmer::kdistance(seqs)  %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column("seqid1") %>%
  gather(key="seqid2", value="sim", -seqid1) %>%
  mutate(sim = 1-sim) %>% # Convert distance to similarity
  mutate(measure = "kdist")

#mbed version
sim_mbed <-  kmer::mbed(seqs)[,]  %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column("seqid1") %>%
  gather(key="seqid2", value="sim", -seqid1) %>%
  mutate(comparison = paste0(seqid1, "-", seqid2)) %>%
  mutate(sim = 1-sim) %>% # Convert distance to similarity
  mutate(measure = "mbed")


all_sim <- bind_rows(sim_tutorial, sim_kdist, sim_mbed) %>%
  mutate(comparison = paste0(seqid1, "-", seqid2))

gg.sim <- ggplot(all_sim, aes(x=comparison, y=sim, colour=measure)) +
  #geom_bar(stat="identity", position="dodge")
  geom_point() +
  facet_grid(~measure)

hist(sim$sim)

```

The results of Somervuo et al. (2016) suggest that a combination of similarity-based and phylogenetic-based predictors yields the best performance both for simulated and real data, however use of phylogenetic-based predictors requires multiple sequence alignment which is slow for datasets in this side

Instead, solely similarity- based predictors can be gained, either usign LAST (Kielbasa et al. 2011), or kmer distance


with the following deviations from the default parameters. We set the LAST argument -T 1 to make the similarity score represent the entire overlap alignment length between two sequences, excluding only the possible overhangs. We set the gap open penalty to (-a 1). In order to get meaningful values to the mean sequence similarity predictor of the PROTAX model, we set the maximum number of initial matches per query position (-m) values between 1000 and 3000 instead of the default value 10. We replaced pairwise sequence similarities that were missing from LAST output by zeros, and converted sequence similarities to the range [0,1] by dividing the alignment score by the alignment length.

    lastdb fwhdb fwhamplicon.fa.gz
    lastal -T 1 -a 1 -m 1000 -f BlastTab fwhdb fwhamplicon.fa.gz > myalns.btab
    
## Create X Matrices 

The input file ‘example_trainseqsim.txt’ contains pairwise sequence similarities in the sparse matrix format, each line consisting of three columns where sim is the similarity between seqid1 and seqid2. Not all pairwise similarities need to be listed in the file. If similarities are symmetric, only one of similarity(seqid1,seqid2) and similarity(seqid2,seqid1) needs to be present in the file. However, if for some reasons the user wants to use asymmetric similarities, then both similarities need to be present in the file in separate lines. If the similarity between two seqids is missing, there are two options, either it is ignored (considered as missing information) or it is treated as being zero. This affects to the calculation of mean similarity. At the moment, missing similarities are treated as missing and mean similarity is calculated only based on present similarities.

```{r}
my_seqsim <- readr::read_tsv("../protax/data/example_trainseqsim.txt", col_names=FALSE) %>%
  magrittr::set_colnames(c("seqid1", "seqid2", "sim"))
head(my_seqsim)
```


In order to create input data for model estimation, we have to construct design matrices related to logistic regression for each training sample. Here the design matrix will be denoted by X. For each training sample, there will be X matrix for each level of the taxonomy starting from the parent node of training sample node and then proceeding to the root. In this example, X matrices are calculated based on sequence similarity file. By default, two values, mean similarity and max similarity are calculated based on pairwise sequence similarities. In addition, there are two other covariates, one for the case when the node does not contain any reference sequences, and another for the intercept of mean and max similarities, so altogether, there are four covariates per taxonomy level

```{r create x matrix}

#could write these to temp files?
protax_create_xmatrix(install="protax",
                      taxonomy= "/protax/data/example_taxonomy.txt",  #Should be able to parse an R taxonomy object
                      repsamples = "/protax/data/my_trainsamples.txt", #
                      trainseq2taxid = "/protax/data/example_trainseqid2taxname.txt",
                      repseqs =  "/protax/data/my_rseqs.txt",
                      seqsim =  "/protax/data/example_trainseqsim.txt",
                      output= "/protax/data/my_trainxdata.txt")
```



The output file ‘my_xdata.txt’ contains one line for each training sample where priprob is the node prior probability (for details, see the manuscript) and the semicolon separated list of items in the second column contain one or more matrices. These are the design matrices of the regression model (denoted as X matrices below). The number of the items depends on the level of the training sample node (in this case only 2), there are matrices for each level from the parent of the training sample node to the root of the taxonomy. Each item has the format

```{r}
my_trainxdata <- readr::read_tsv("../protax/data/my_trainxdata.txt", col_names=FALSE) %>%
  magrittr::set_colnames(c("priprob", "item1", "item2"))
head(my_trainxdata)
```


• level,index,nrows,ncols,x11,x12,...,xNM

where level indicates which level of taxonomy the N-by-M matrix X belongs, index is the child node index where the current training sample belongs in this taxonomy level, nrows and ncols are the number of rows and columns of matrix X, respectively, and the rest nrows*ncols values are the elements of X listed row by row. The first row of each matrix which corresponds to the unknown taxon contains only zeros. Since the xdata file will be used in R software where array element indexing starts from 1 instead of 0, also here the index corresponding to the first row of matrix X is 1 instead of 0.


# Step 2 Estimating model parameters

Input to the model parameter estimation is given by xdat-file. The parameter estimation is done using R. For MCMC estimation, all required functions are in the file amcmc.rcode.txt.

In our example xdata, there are 4 parameters for each level of the taxonomy and an additional parameter for mislabeling probability, so the total number of parameters is 2*4+1=9. Besides training data, we have to define variance s2 of prior distribution (zero-mean Normal distribution), number of iterations, and how many of them are used for adaptation (num.burnin). Additional parameters are random seed (rseed) and info. By default, info is 0 which results in silent processing, but when it is 1, we can see the progress of the iterations. Here we apply only 1000 iterations but in practice there should be more.

Variance of prior distribution has been set large (10000) in order not to restrict the values of parameters. However, the smaller the range of similarity values is, the larger the prior variance should be in order to allow large value for the coefficients related to sequence similarity, i.e. allowing steeper slope in the regression model. In general, all covariates should be scaled properly before using them in PROTAX.

```{r mcmc}
#Source scripts
source("../protax/scripts/amcmc.rcode.txt")

# Read in data
dat=read.xdata("../protax/data/my_trainxdata.txt")

# Estimate model parameters
pp=adaptiveMCMC(dat, num.params=9 ,s2=10000, num.iterations=1000, num.burnin=500, rseed=1, info=1)
```

After training, it is good practice to check trace plots. In R it is simple to plot the values of parameters during the entire MCMC history. Here we are interested in the values after burn-in, so we can plot the parameter samples between iterations 501 and 1000.

Parameter num.levels is the number of levels in our taxonomy, it helps to layout the plot so that parameters from each level are located in the same row. Values corresponding to the largest posterior probability (MAP estimate) within the given iterations are denoted by red circle. Panels next to each individual trace plot show the histograms of the parameter values. This way it is easy to see e.g. whether the MAP estimate is close to the mode of the distribution.

In case there are too many parameters to fit into a single display, trace plots of individual parameters can be visualized using command traceplot.one. Since it produces two figures, we define mfrow to split the display into two subplots.

If trace plots indicate non-convergence, usually another round of adaptation helps to solve the problem. The result of MCMC adaptation can be investigated by amcmc.diagnostic.plot. In addition to acceptance ratios, it shows the adaptive step size and proposal directions. The latter are the eigenvectors of parameter covariance matrix. Parameters may be correlated by incidence due to the random initialization. Diagnostic plot reveals which parameters are correlated in MCMC proposal.

```{r mcmc diagnostics}
#Traceplot
traceplot.all(pp,ind=501:1000,num.levels=2,title="my MCMC")

#Diagnostic plot
amcmc.diagnostic.plot(pp)
 
#Acceptance	ratios	should	be	close	to	0.44,
pp$ac/pp$cc

#Step size for each dimension
pp$k
```

If the Markov chain is not mixing well, usually some parameters are correlated, either due to random initialization or otherwise. The following demonstrates how to continue training from previous MCMC state with new adaptation. Here we use last value of previous MCMC chain for parameter estimates but initialize other values (adaptation step size and proposal direction vectors

```{r }
initstate=initialize.adaptation(pp$params[1000,])
pp=adaptiveMCMC(dat, num.params=9 , s2=10000, num.iterations=1000, num.burnin=500, rseed=1, info=1, prev.state=initstate)


traceplot.all(pp,ind=501:1000,num.levels=2,title="my MCMC\nafter re-adaptation")
```


When we are satisfied with MCMC training, the posterior samples can be saved. Either we can save the entire chain, or values after burn-in, e.g. the following writes all values starting from iteration 501

Alternatively,	we	can	choose	a	single	parameter	vector	corresponding	to	the	largest	posterior	
probability	within	iterations	501-1000	(MAP	estimate)

```{r}
#Write all
write.postparams(pp,"../protax/data/my_mcmc.txt",501:1000)

#Write largest posterior probs
ind=501:1000
i=which.max(pp$postli[ind])
write.postparams(pp,"../protax/data/my_mcmc.txt",ind[i])
```

The output MCMC sample file is a text file where the first value in each line is the posterior probability of the sample and the rest are the parameter values, i.e. if there are 9 parameters, each line contains 10 numbers.

#Step 3 Classifying new sequence data

After the model has been trained, new sequences can be classified. Here we use validation data which are the sequences which were not present in the model training but we know their true taxonomic labels. Therefore they can be used as an independent data set to validate the model. The first file ‘example_testseqids.txt’ contains all sequence ids which we want to classify. Sequence similarities between them and representative sequences are in ‘example_testseqsim.txt

Note - would be best to adapt this function to directly take in a fasta file or DNAbin and produce these files

```{r}

#To parse r objects, may need to make temp files and delete them after classification

#might be worth doing nodeprob etc = TRUE then any reformatting etc is done in R - only use perl for the nitty gritty classification

x <- protax_classify(install="protax",
                      seqids= "/protax/data/example_testseqids.txt", #should be able to parse a DNABin and this creates this and below
                      seqsim =  "/protax/data/example_testseqsim.txt",
                      taxonomy= "/protax/data/example_taxonomy.txt", # Find a way to parse an R taxonomy object
                      trainseq2taxid = "/protax/data/example_trainseqid2taxname.txt", #Why is this even needed?
                      repseqs =  "/protax/data/my_rseqs.txt", #reference sequences used for training - this should be able to be a DNAbin
                      mcmc="/protax/data/my_mcmc.txt", # Parse the mcmc results directly in R
                      output= "/protax/data/my_testclas.txt", #Would be nice to return an R object
                      type="map",
                      n_outcomes=0, # Output all probabilities
                      threshold =0.1, # Dont bother with any below 0.01
                      add_tax=TRUE,
                      validation=FALSE,
                      verbose=TRUE,
                     nodeprob=TRUE)

```

